<div align="center">

# ğŸ›¡ï¸ Self-Healing ML Microservice Mesh

### A Production-Grade, Resilient Machine Learning Platform for Real-Time Fraud Detection

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)](https://docker.com)
[![MLflow](https://img.shields.io/badge/MLflow-2.9+-0194E2?logo=mlflow&logoColor=white)](https://mlflow.org)
[![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-E6522C?logo=prometheus&logoColor=white)](https://prometheus.io)
[![Grafana](https://img.shields.io/badge/Grafana-Dashboards-F46800?logo=grafana&logoColor=white)](https://grafana.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

*Beyond model training â€” this project demonstrates real-world ML engineering: versioned models, live traffic routing, automated retraining, observability, and fault tolerance under production constraints.*

</div>

---

## ğŸ“‘ Table of Contents

- [Why This Project](#-why-this-project)
- [System Architecture](#-system-architecture)
- [Key Capabilities](#-key-capabilities)
- [How It Works](#-how-it-works)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Getting Started](#-getting-started)
- [Usage & API Reference](#-usage--api-reference)
- [Observability & Dashboards](#-observability--dashboards)
- [Resilience & Self-Healing](#-resilience--self-healing)
- [Testing](#-testing)
- [CI/CD Pipeline](#-cicd-pipeline)
- [Kubernetes Deployment](#-kubernetes-deployment-optional)
- [Design Decisions](#-design-decisions)
- [License](#-license)

---

## ğŸ¯ Why This Project

Most ML portfolios stop at Jupyter notebooks and accuracy metrics. Production ML is fundamentally different â€” it requires:

| Production Challenge | How This Project Addresses It |
|---|---|
| **Model Versioning** | MLflow registry with multiple model versions |
| **Safe Deployments** | Canary routing with configurable traffic splits |
| **Failure Recovery** | Circuit breakers, cascading failover, heuristic fallback |
| **Data Drift** | KS test + PSI statistical monitoring on live features |
| **Auto-Retraining** | Prefect pipeline triggered on drift detection |
| **Observability** | Prometheus metrics + Grafana dashboards (P50/P95/P99) |
| **Scalability** | Docker Compose + optional Kubernetes with HPA |

This system runs a **tabular fraud detection use case** with synthetic transactional data â€” but the architecture is generalizable to any ML workload.

---

## ğŸ—ï¸ System Architecture

### High-Level Overview

```mermaid
graph TB
    subgraph Client Layer
        CL[Client / Load Test]
    end

    subgraph API Gateway :8000
        GW[FastAPI Gateway]
        RT[Traffic Router]
        SH[Shadow Evaluator]
        RB[Rollback Manager]
    end

    subgraph Inference Layer
        XGB[ğŸŒ² XGBoost Service :8001]
        PT[ğŸ”¥ PyTorch Service :8002]
        FB[ğŸ“ Fallback Heuristic :8003]
    end

    subgraph Data Layer
        RD[(Redis :6379<br/>Feature Store)]
        MLF[ğŸ“Š MLflow :5000<br/>Model Registry]
    end

    subgraph Observability
        PROM[ğŸ“ˆ Prometheus :9090]
        GRAF[ğŸ“‰ Grafana :3000]
    end

    subgraph ML Lifecycle
        DD[ğŸ” Drift Detector]
        RE[ğŸ”„ Prefect Retraining]
    end

    CL -->|POST /api/v1/predict| GW
    GW --> RT
    RT -->|80% traffic| XGB
    RT -->|20% traffic| PT
    RT -.->|fallback| FB
    SH -.->|shadow eval| PT

    GW --> RD
    RE --> MLF
    RD --> DD
    DD -->|drift trigger| RE
    RE -->|deploy canary| GW

    XGB --> PROM
    PT --> PROM
    GW --> PROM
    PROM --> GRAF

    style GW fill:#1a1a2e,color:#e94560
    style XGB fill:#0f3460,color:#e94560
    style PT fill:#0f3460,color:#e94560
    style FB fill:#533483,color:#e94560
    style PROM fill:#16213e,color:#e94560
    style GRAF fill:#16213e,color:#e94560
```

### Request Flow â€” What Happens on a Prediction Call

```mermaid
sequenceDiagram
    participant C as ğŸ§‘ Client
    participant GW as ğŸšª API Gateway
    participant R as âš–ï¸ Router
    participant XGB as ğŸŒ² XGBoost
    participant PT as ğŸ”¥ PyTorch
    participant FB as ğŸ“ Fallback
    participant FS as ğŸ’¾ Redis

    C->>GW: POST /api/v1/predict
    GW->>FS: Log input features
    GW->>R: Select service (weighted random)

    alt 80% â”€ Primary Route
        R->>XGB: Forward request
        XGB-->>R: {fraud_probability: 0.87}
    else 20% â”€ Canary Route
        R->>PT: Forward request
        PT-->>R: {fraud_probability: 0.82}
    end

    opt Shadow Mode Enabled
        R-->>PT: Async shadow call (fire & forget)
        Note right of PT: Shadow result logged,<br/>not returned to client
    end

    alt âš¡ Circuit Breaker Opens
        R->>FB: Rule-based fallback
        FB-->>R: {fraud_probability: 0.65}
    end

    R-->>GW: Response + routing metadata
    GW-->>C: JSON response
```

### ML Lifecycle â€” Retraining & Self-Healing Loop

```mermaid
flowchart LR
    subgraph Monitor
        A[ğŸ“Š Live Traffic] --> B[ğŸ“ Feature Store]
        B --> C{ğŸ” Drift<br/>Detected?}
    end

    subgraph Retrain
        C -->|Yes| D[ğŸ“¦ Generate<br/>Fresh Data]
        D --> E[ğŸ‹ï¸ Retrain<br/>XGBoost]
        E --> F[ğŸ“ Log to<br/>MLflow]
        F --> G[âœ… Register<br/>New Version]
    end

    subgraph Deploy
        G --> H[ğŸ¤ Deploy as<br/>Canary 10%]
        H --> I{ğŸ“ˆ Canary<br/>Healthy?}
        I -->|âœ… Yes| J[ğŸš€ Promote<br/>to 100%]
        I -->|âŒ No| K[âª Auto<br/>Rollback]
    end

    C -->|No| L[âœ… Continue<br/>Monitoring]

    style C fill:#ff9800,color:#000
    style I fill:#ff9800,color:#000
    style J fill:#4caf50,color:#fff
    style K fill:#f44336,color:#fff
```

---

## ğŸ”‘ Key Capabilities

### ğŸ§  Multi-Model Inference
- **XGBoost v1** â€” Gradient-boosted tree classifier (primary model)
- **PyTorch MLP v1** â€” 3-layer neural network with BatchNorm (canary/secondary)
- **Fallback Heuristic** â€” Rule-based scoring (zero ML dependency, always available)

### ğŸ”€ Intelligent Traffic Routing
- Weighted random routing with configurable splits (e.g., 80/20)
- Dynamic traffic updates via API (`POST /api/v1/traffic`)
- **Shadow evaluation** â€” new models receive live traffic and log predictions without affecting responses

### ğŸ›¡ï¸ Circuit Breaker & Failover
```
Primary Model â”€â”€[fails]â”€â”€> Alternate ML Model â”€â”€[fails]â”€â”€> Heuristic Fallback â”€â”€[fails]â”€â”€> Conservative Default
     â†‘                                                                                           â”‚
     â””â”€â”€â”€ Recovery (HALF_OPEN probe) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

States: **CLOSED** (healthy) â†’ **OPEN** (after N failures) â†’ **HALF_OPEN** (recovery probe after timeout)

### ğŸ“‰ Drift Detection
- **KS Test** (Kolmogorov-Smirnov) â€” Detects distribution shifts per feature
- **PSI** (Population Stability Index) â€” Measures magnitude of shift
  - PSI < 0.1 â†’ No action
  - 0.1 â‰¤ PSI < 0.2 â†’ Monitor closely
  - PSI â‰¥ 0.2 â†’ Trigger retraining

### ğŸ”„ Automated Retraining
Prefect orchestrates a 5-step pipeline:
1. Check drift scores â†’ decide if retraining needed
2. Generate fresh synthetic data
3. Retrain model with MLflow logging
4. Register new version in model registry
5. Deploy as canary (10% traffic)

### ğŸ“Š Observability
Every service exposes `/metrics` for Prometheus, with a pre-built Grafana dashboard covering:

| Metric | Type | Description |
|--------|------|-------------|
| Latency P50/P95/P99 | Histogram | Per-service response time percentiles |
| RPS | Counter | Requests per second by model version |
| Error Rate | Gauge | % of failed requests with color thresholds |
| Traffic Distribution | Pie Chart | Visual split across XGBoost / PyTorch / Fallback |
| Service Health | Status | UP/DOWN per service |
| Fallback Usage | Counter | Tracks when ML services are degraded |
| Prediction Classes | Counter | Fraud vs. legitimate prediction rates |

---

## âš™ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **ML Models** | XGBoost, PyTorch | Fraud classification |
| **API** | FastAPI, Uvicorn | High-performance async service layer |
| **Routing** | Custom Python | Weighted routing, circuit breaker, shadow eval |
| **Feature Store** | Redis Streams | Online feature logging & retrieval |
| **Drift Detection** | SciPy (KS test), Custom PSI | Statistical distribution monitoring |
| **Experiment Tracking** | MLflow | Model registry, param/metric logging |
| **Orchestration** | Prefect | Automated retraining DAG |
| **Monitoring** | Prometheus + Grafana | Metrics collection & dashboards |
| **Containerization** | Docker, Docker Compose | Service isolation & orchestration |
| **Scaling** | Kubernetes (HPA) | Horizontal pod autoscaling |
| **CI/CD** | GitHub Actions | Lint, test, build, security scan |
| **Load Testing** | Locust | Concurrent traffic simulation |

---

## ğŸ“ Project Structure

```
Self_healing_ML_mesh/
â”‚
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ generate_dataset.py          # Synthetic fraud transaction generator (50k rows)
â”‚
â”œâ”€â”€ ğŸ‹ï¸ training/
â”‚   â”œâ”€â”€ feature_engineering.py       # Shared feature transforms (train-serve parity)
â”‚   â”œâ”€â”€ train_xgboost.py             # XGBoost training + MLflow logging
â”‚   â”œâ”€â”€ train_pytorch.py             # PyTorch MLP training + MLflow logging
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸš€ inference/
â”‚   â”œâ”€â”€ xgboost_service/             # XGBoost model server (FastAPI + Docker)
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ pytorch_service/             # PyTorch model server (FastAPI + Docker)
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ fallback_service/            # Rule-based heuristic fallback
â”‚       â”œâ”€â”€ app.py
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸšª gateway/
â”‚   â”œâ”€â”€ app.py                       # API gateway (single entry point)
â”‚   â”œâ”€â”€ router.py                    # Weighted routing + circuit breaker
â”‚   â”œâ”€â”€ shadow.py                    # Shadow evaluation pipeline
â”‚   â”œâ”€â”€ rollback.py                  # Auto-rollback on canary degradation
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ’¾ feature_store/
â”‚   â”œâ”€â”€ store.py                     # Redis-backed online feature store
â”‚   â”œâ”€â”€ drift.py                     # KS test + PSI drift detection
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ”„ retraining/
â”‚   â”œâ”€â”€ retrain_flow.py              # Prefect automated retraining DAG
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ˆ monitoring/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ prometheus.yml           # Scrape configuration
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ provisioning/            # Auto-provisioned datasources & dashboards
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”‚       â””â”€â”€ ml_mesh.json         # Pre-built Grafana dashboard (10 panels)
â”‚   â””â”€â”€ alerting/
â”‚       â””â”€â”€ rules.yml                # Prometheus alert rules
â”‚
â”œâ”€â”€ â˜¸ï¸ k8s/
â”‚   â”œâ”€â”€ deployments/
â”‚   â”‚   â””â”€â”€ services.yml             # K8s deployments + services
â”‚   â””â”€â”€ hpa.yml                      # Horizontal Pod Autoscaler configs
â”‚
â”œâ”€â”€ ğŸ§ª tests/
â”‚   â”œâ”€â”€ test_inference.py            # Feature engineering + data gen tests
â”‚   â”œâ”€â”€ test_gateway.py              # Router + circuit breaker tests
â”‚   â”œâ”€â”€ test_drift.py                # KS/PSI drift detection tests
â”‚   â””â”€â”€ test_feature_store.py        # Feature store integration tests
â”‚
â”œâ”€â”€ ğŸ”¥ loadtest/
â”‚   â””â”€â”€ locustfile.py                # Locust load test (normal + burst traffic)
â”‚
â”œâ”€â”€ ğŸ“– architecture/
â”‚   â””â”€â”€ ARCHITECTURE.md              # Detailed architecture docs with Mermaid diagrams
â”‚
â”œâ”€â”€ ğŸ”§ .github/workflows/
â”‚   â””â”€â”€ ci.yml                       # GitHub Actions CI pipeline
â”‚
â”œâ”€â”€ docker-compose.yml               # 8 services orchestrated
â”œâ”€â”€ Makefile                          # Common commands
â”œâ”€â”€ .env.example                     # Environment variable template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                        # You are here!
```

---

## ğŸš€ Getting Started

### Prerequisites

| Tool | Version | Purpose |
|------|---------|---------|
| Python | 3.11+ | Runtime |
| Docker | 20.10+ | Containerization |
| Docker Compose | v2+ | Orchestration |
| Git | Any | Version control |

### Step 1 â€” Clone & Configure

```bash
git clone git@github.com:ShreyasVR2545/Self_healing_ML_mesh.git
cd Self_healing_ML_mesh
cp .env.example .env
```

### Step 2 â€” Generate Data & Train Models

```bash
# Install training dependencies
pip install -r training/requirements.txt

# Generate synthetic fraud dataset (50,000 transactions, ~2% fraud rate)
python data/generate_dataset.py
# Output: data/transactions.csv

# Train XGBoost baseline model (logs to MLflow)
python training/train_xgboost.py
# Output: models/xgboost_v1.json + MLflow experiment

# Train PyTorch MLP model (logs to MLflow)
python training/train_pytorch.py
# Output: models/pytorch_v1.pt + MLflow experiment
```

**Expected training output:**
```
Training XGBoost model...
  auc_roc:   0.9847
  f1:        0.8234
  precision: 0.8891
  recall:    0.7672
Model registered as 'fraud-xgboost'
```

### Step 3 â€” Launch All Services

```bash
# Build and start all 8 services
docker-compose build
docker-compose up -d

# Verify all services are healthy
docker-compose ps
```

**Services launched:**

| Service | URL | Status |
|---------|-----|--------|
| API Gateway | http://localhost:8000 | ğŸŸ¢ |
| XGBoost Service | http://localhost:8001 | ğŸŸ¢ |
| PyTorch Service | http://localhost:8002 | ğŸŸ¢ |
| Fallback Service | http://localhost:8003 | ğŸŸ¢ |
| MLflow | http://localhost:5000 | ğŸŸ¢ |
| Redis | localhost:6379 | ğŸŸ¢ |
| Prometheus | http://localhost:9090 | ğŸŸ¢ |
| Grafana | http://localhost:3000 | ğŸŸ¢ |

### Step 4 â€” Send Your First Prediction

```bash
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{
    "amount": 1500.00,
    "merchant_category": 7,
    "hour_of_day": 2,
    "day_of_week": 6,
    "distance_from_home": 150.0,
    "distance_from_last_txn": 80.0,
    "is_foreign": 1,
    "velocity_last_1h": 5,
    "velocity_last_24h": 12,
    "avg_amount_last_7d": 200.0,
    "card_age_days": 15
  }'
```

**Response:**
```json
{
  "fraud_probability": 0.874532,
  "is_fraud": true,
  "model_version": "xgboost_v1",
  "model_type": "xgboost",
  "latency_ms": 12.45,
  "routed_to": "xgboost",
  "fallback_reason": null
}
```

---

## ğŸ“š Usage & API Reference

### Gateway Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/predict` | Submit transaction for fraud scoring |
| `GET` | `/health` | Gateway + service health status |
| `GET` | `/api/v1/status` | Full system status (routing, shadow, rollback) |
| `POST` | `/api/v1/traffic` | Dynamically update traffic split weights |
| `GET` | `/metrics` | Prometheus-compatible metrics |

### Prediction Request Schema

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `amount` | float | âœ… | Transaction amount (USD) |
| `merchant_category` | int | âœ… | Category code (0-9) |
| `hour_of_day` | int | âœ… | Hour (0-23) |
| `day_of_week` | int | âœ… | Day (0=Mon, 6=Sun) |
| `distance_from_home` | float | âœ… | Distance in km |
| `distance_from_last_txn` | float | âœ… | Distance from last transaction |
| `is_foreign` | int | âœ… | International transaction (0/1) |
| `velocity_last_1h` | int | âœ… | Transactions in last hour |
| `velocity_last_24h` | int | âœ… | Transactions in last 24 hours |
| `avg_amount_last_7d` | float | âœ… | 7-day average transaction amount |
| `card_age_days` | int | âœ… | Card age in days |

### Dynamic Traffic Control

```bash
# Split traffic 50/50 between XGBoost and PyTorch
curl -X POST http://localhost:8000/api/v1/traffic \
  -H "Content-Type: application/json" \
  -d '{"xgboost": 0.5, "pytorch": 0.5}'

# Send 100% to XGBoost (disable canary)
curl -X POST http://localhost:8000/api/v1/traffic \
  -H "Content-Type: application/json" \
  -d '{"xgboost": 1.0, "pytorch": 0.0}'
```

---

## ğŸ“Š Observability & Dashboards

### Grafana Dashboard

Access at **http://localhost:3000** (login: `admin` / `admin`)

The pre-provisioned dashboard includes **10 panels**:

| Panel | Type | What It Shows |
|-------|------|---------------|
| Gateway RPS | Time Series | Requests/second by model version |
| Latency Percentiles | Time Series | P50, P95, P99 end-to-end latency |
| Error Rate | Gauge | % errors with green/yellow/red thresholds |
| Traffic Distribution | Pie Chart | % split across XGBoost / PyTorch / Fallback |
| Active Requests | Stat | Currently in-flight requests |
| Service Health | Stat | UP/DOWN per service |
| XGBoost Latency | Time Series | Per-service P50/P95 latency |
| PyTorch Latency | Time Series | Per-service P50/P95 latency |
| Prediction Classes | Time Series | Fraud vs. legit prediction rate |
| Fallback Usage | Time Series | Fallback service request rate |

### Prometheus Alerts

| Alert | Condition | Severity |
|-------|-----------|----------|
| `HighGatewayLatency` | P95 > 500ms for 2min | âš ï¸ Warning |
| `HighErrorRate` | Error rate > 5% for 2min | ğŸ”´ Critical |
| `ServiceDown` | Service unreachable for 1min | ğŸ”´ Critical |
| `HighFallbackUsage` | Fallback > 1 req/s for 5min | âš ï¸ Warning |

---

## ğŸ›¡ï¸ Resilience & Self-Healing

### Circuit Breaker State Machine

```mermaid
stateDiagram-v2
    [*] --> CLOSED: Service starts
    CLOSED --> OPEN: N consecutive failures
    OPEN --> HALF_OPEN: Recovery timeout expires
    HALF_OPEN --> CLOSED: Probe succeeds
    HALF_OPEN --> OPEN: Probe fails
    
    CLOSED: âœ… Accepting traffic normally
    OPEN: âŒ Rejecting all traffic
    HALF_OPEN: ğŸ”„ Testing with single probe request
```

### Cascading Failover Strategy

```mermaid
flowchart LR
    A[Request] --> B{Primary Model<br/>Available?}
    B -->|Yes| C[âœ… XGBoost Response]
    B -->|No| D{Alternate Model<br/>Available?}
    D -->|Yes| E[âœ… PyTorch Response]
    D -->|No| F{Fallback Service<br/>Available?}
    F -->|Yes| G[âš ï¸ Heuristic Response]
    F -->|No| H[ğŸš¨ Conservative Default<br/>Flag as Fraud]

    style C fill:#4caf50,color:#fff
    style E fill:#4caf50,color:#fff
    style G fill:#ff9800,color:#000
    style H fill:#f44336,color:#fff
```

### Auto-Rollback

The rollback manager runs a background health check loop:

1. Every 10 seconds, probes each model's `/health` endpoint
2. Tracks rolling error rate and P95 latency
3. **If error rate > 10% OR P95 latency > 500ms** â†’ triggers automatic rollback
4. Rolled-back service gets 0% traffic weight
5. Remaining traffic redistributed to healthy services
6. Rollback events are logged with timestamps and reasons

---

## ğŸ§ª Testing

### Unit Tests

```bash
# Run all 30 tests
python -m pytest tests/ -v

# Run specific test suite
python -m pytest tests/test_drift.py -v       # Drift detection (9 tests)
python -m pytest tests/test_gateway.py -v      # Gateway routing (10 tests)
python -m pytest tests/test_inference.py -v    # Inference + features (8 tests)
python -m pytest tests/test_feature_store.py -v # Feature store (3 tests)
```

**Test coverage:**

| Suite | Tests | Coverage |
|-------|-------|----------|
| `test_drift.py` | 9 | KS test, PSI, DriftDetector |
| `test_gateway.py` | 10 | Circuit breaker, routing, shadow |
| `test_inference.py` | 8 | Feature engineering, data gen, heuristics |
| `test_feature_store.py` | 3 | Redis store (mocked) |
| **Total** | **30** | âœ… **All passing** |

### Load Testing

```bash
# Headless mode â€” 50 concurrent users, 30 second duration
cd loadtest
locust -f locustfile.py --headless -u 50 -r 10 -t 30s --host http://localhost:8000

# Web UI mode â€” opens browser dashboard
locust -f locustfile.py --host http://localhost:8000
# â†’ Open http://localhost:8089
```

The load test simulates:
- **Normal traffic** (90%): Typical transactions with realistic feature distributions  
- **Suspicious traffic** (10%): High-amount, foreign, nighttime transactions  
- **Burst patterns**: Rapid-fire requests to test under spike conditions  

---

## ğŸ”§ CI/CD Pipeline

The GitHub Actions pipeline (`.github/workflows/ci.yml`) runs on every push and PR:

```mermaid
flowchart LR
    A[Push / PR] --> B[ğŸ” Lint<br/>ruff check]
    B --> C[ğŸ§ª Unit Tests<br/>pytest]
    C --> D[ğŸ³ Docker Build<br/>Validation]
    B --> E[ğŸ”’ Security Scan<br/>bandit]

    style B fill:#2196F3,color:#fff
    style C fill:#4caf50,color:#fff
    style D fill:#9c27b0,color:#fff
    style E fill:#f44336,color:#fff
```

| Stage | Tool | What It Does |
|-------|------|-------------|
| Lint | Ruff | Fast Python linting |
| Test | Pytest | Runs 30 unit tests with JUnit XML output |
| Build | Docker | Validates Dockerfiles compile correctly |
| Security | Bandit | Static analysis for common security issues |

---

## â˜¸ï¸ Kubernetes Deployment (Optional)

For production-grade scaling, Kubernetes manifests are provided:

```bash
# Apply deployments + services
kubectl apply -f k8s/deployments/services.yml

# Apply Horizontal Pod Autoscalers
kubectl apply -f k8s/hpa.yml
```

**HPA Configuration:**

| Service | Min Replicas | Max Replicas | Scale Trigger |
|---------|-------------|-------------|---------------|
| XGBoost | 2 | 10 | CPU > 70% |
| PyTorch | 1 | 5 | CPU > 70% |
| Gateway | 2 | 8 | CPU > 70% |

---

## ğŸ’¡ Design Decisions

| Decision | Rationale |
|----------|-----------|
| **FastAPI over Flask** | Native async support, automatic OpenAPI docs, Pydantic validation, significantly better throughput |
| **Synthetic data over Kaggle** | Reproducible, no download dependencies, controllable fraud ratio and feature distributions |
| **Prefect over Airflow** | Lighter weight, pure Python, easier to containerize, better for small-to-medium workflows |
| **Redis Streams over PostgreSQL** | Sub-millisecond feature logging, natural time-series ordering, perfect for high-throughput feature stores |
| **Shared `feature_engineering.py`** | Guarantees train-serve parity â€” the exact same transforms run in training and in every inference service |
| **Conservative emergency fallback** | When ALL services are down, flag as fraud (false positive > false negative for financial fraud) |
| **Circuit breaker per service** | Independent failure isolation â€” one service crashing doesn't bring down the entire mesh |

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.

---

<div align="center">

**Built with â¤ï¸ by [Shreyas](https://github.com/ShreyasVR2545)**

*Demonstrating that production ML is about far more than model accuracy.*

</div>
